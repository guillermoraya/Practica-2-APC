{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducció a la pràctica 2\n",
    "\n",
    "## Objectius\n",
    "\n",
    "Els objectius d'aquesta pràctica són:\n",
    "  \n",
    "* Aplicar models de classificació, ficant l'èmfasi en:\n",
    "    1. Aplicar diferents classificadors (regressor logístic i svm) i entendre les millores d'aplicar kernels.\n",
    "    2. Avaluar correctament l'error del model \n",
    "    3. Visualitzar les dades i el model resultant\n",
    "\n",
    "\n",
    "* Ésser capaç d'aplicar tècniques de classificació en casos reals\n",
    "\n",
    "* Validar els resultats en dades reals\n",
    "\n",
    "* Fomentar la capacitat per presentar resultats tècnics d'aprenentatge computacional de forma adequada davant altres persones\n",
    "\n",
    "\n",
    "## Bases de dades\n",
    "\n",
    "Cada grup utilitzarà les bases de dades que se li hagin assignat depenent del grup on s'ha apuntat al caronte. \n",
    "\n",
    "\n",
    "| # | GRUP | BASE DE DADES ASSIGNADA|\n",
    "|:-:|:-:|:--|\n",
    "|\t1\t|\tGA\\*01-0000\t| https://www.kaggle.com/rounakbanik/pokemon\t|\n",
    "|\t2\t|\tGA\\*02-0000\t| https://www.kaggle.com/c/titanic/data\t|\n",
    "|\t3\t|\tGA\\*03-0000\t| https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\t|\n",
    "|\t4\t|\tGA\\*04-0000\t|https://www.kaggle.com/iabhishekofficial/mobile-price-classification\t|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Avaluació i entregues de la pràctica 2\n",
    "\n",
    "En la pràctica 2, es presenten diversos problemes per comprendre els mètodes de classificació numèrica.\n",
    "\n",
    "Les entregues s'organitzen en dos nivells d'assoliment dels objectius, incrementals: apartat **B, (sobre 6 punts)**, assoliment baix; apartat **A, (sobre 4 punts)**, assoliment alt. La suma dels 2 apartats serà la nota final de la pràctica 2. Per a realitzar el apartat A, prèviament s'ha d'haver resolt l'apartat B.\n",
    "\n",
    "Per cada apartat s'utilitzarà una base de dades diferent. A l'apartat B, treballarem majoritariament amb dades numèriques i es farà servir per establir les bases i l'esquelet per l'apartat A, on hi trobarem unes dades molt més riques i complexes.\n",
    "\n",
    "Similarment a la sessió de de treball de la pràctica 1, a la sessió de treball es molt recomanat que pregunteu sobre les bases de dades assignades, els problemes que heu de resoldre, per si hi haguéssin errors amb les llibreries o les seves funcions, aclaracions sobre les preguntes a contestar i els metodes a aplicar...\n",
    "\n",
    "Així, aquesta sessió de treball està orientada a que, els alumnes que vingueu pugueu preguntar i resoldre dubtes sobre les bases de dades que us han estat assignades, preguntar sobre l'objectiu de cada apartat dels enunciats que no us hagi quedat clar, i preguntar sobre els resultats que esteu obtenint a l'hora d'analitzar les dades. A més, podreu veure com els vostres companys estan resolent altres bases de dades, per agafar idees i veure com altres problemes es poden solucionar amb els mètodes que heu vist a classe de teoria.\n",
    "\n",
    "I en la següent sessió del 25 de novembre s'evaluarà la **pràctica sencera amb els dos apartats**. Caldrà pujar al Caronte abans de les 00:59 del dimecres 24 de novembre un ZIP amb el codi, la documentació i el ppt (10 minuts).\n",
    "\n",
    "   * Entrega (Apartat B 6pts + Apartat A 4pts)\n",
    "     1. Memòria en format article explicant els resultats trobats sobre la bases de dades de l'apartat B i els experiments realitzats sobre la base de dades A (10-50 pàgs). (4pts + 2.5pts)\n",
    "     2. Codi python desenvolupat. (1.5pts + 1pts)\n",
    "     3. Presentació amb els resultats 4 min màxim. (0.5pts + 0.5pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (B): Comparativa de models (4pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "n_classes = 3\n",
    "    \n",
    "fig, sub = plt.subplots(1, 2, figsize=(16,6))\n",
    "sub[0].scatter(X[:,0], y, c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "sub[1].scatter(X[:,1], y, c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "\n",
    "\n",
    "particions = [0.5, 0.7, 0.8]\n",
    "\n",
    "for part in particions:\n",
    "    x_t, x_v, y_t, y_v = train_test_split(X, y, train_size=part)\n",
    "    \n",
    "    #Creem el regresor logístic\n",
    "    logireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\n",
    "\n",
    "    # l'entrenem\n",
    "    logireg.fit(x_t, y_t)\n",
    "\n",
    "    print (\"Correct classification Logistic \", part, \"% of the data: \", logireg.score(x_v, y_v))\n",
    "    \n",
    "    #Creem el regresor logístic\n",
    "    svc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9, probability=True)\n",
    "\n",
    "    # l'entrenem \n",
    "    svc.fit(x_t, y_t)\n",
    "    probs = svc.predict_proba(x_v)\n",
    "    print (\"Correct classification SVM      \", part, \"% of the data: \", svc.score(x_v, y_v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal com podeu llegir a [l'API de sklearn](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html), en comptes de fer una corba per cada classe, podem considerar totes les classes en conjunt en una sola corba (1 si hem predit la classe correcta, 0 si no). Això es coneix com a `micro-averaging`. \n",
    "\n",
    "Així, veureu que la funció `f1_score` utilitza el paràmetre `macro` per calcular la precision-recall-f1 per clase, i després fer la mitja pr a totes les classes; i `micro` per utilitzar totes les prediccions (i errors de FN, FP) per a calcular una única precision-recall-f1 per a totes les classes juntes.\n",
    "\n",
    "Si voleu calcular la corba Precision-Recall quan utilitzeu el K-fold, cal calcular les corbes per a cada fold i després [fer la mitja de tots els folds per obtenir la corba final](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py). En el cas del LOOCV no té sentit fer la mitja la corba PR perquè hauriem de fer servir totes les mostres com a $y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = {}\n",
    "recall = {}\n",
    "average_precision = {}\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_v == i, probs[:, i])\n",
    "    average_precision[i] = average_precision_score(y_v == i, probs[:, i])\n",
    "\n",
    "    plt.plot(recall[i], precision[i],\n",
    "    label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
    "                           ''.format(i, average_precision[i]))\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    \n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_v == i, probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "def show_C_effect(C=1.0, gamma=0.7, degree=3):\n",
    "\n",
    "    # import some data to play with\n",
    "    iris = datasets.load_iris()\n",
    "    # Take the first two features. We could avoid this by using a two-dim dataset\n",
    "    X = iris.data[:, :2]\n",
    "    y = iris.target\n",
    "\n",
    "    # we create an instance of SVM and fit out data. We do not scale our\n",
    "    # data since we want to plot the support vectors\n",
    "    # title for the plots\n",
    "    titles = ('SVC with linear kernel',\n",
    "              'LinearSVC (linear kernel)',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with polynomial (degree 3) kernel')\n",
    "\n",
    "    #C = 1.0  # SVM regularization parameter\n",
    "    models = (svm.SVC(kernel='linear', C=C),\n",
    "              svm.LinearSVC(C=C, max_iter=1000000),\n",
    "              svm.SVC(kernel='rbf', gamma=gamma, C=C),\n",
    "              svm.SVC(kernel='poly', degree=degree, gamma='auto', C=C))\n",
    "    models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "    plt.close('all')\n",
    "    fig, sub = plt.subplots(2, 2, figsize=(14,9))\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    X0, X1 = X[:, 0], X[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "    for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "        plot_contours(ax, clf, xx, yy,\n",
    "                      cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "        ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xlabel('Sepal length')\n",
    "        ax.set_ylabel('Sepal width')\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podeu provar quin efecte té diferents valors de regularització per aquest petit exemple ( C=0.0001 to 1000..). També podeu veure com afecta els valors de degree i gamma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_C_effect(C=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (A): Classificació Numèrica (6pts)\n",
    "\n",
    "Per a aquest primer apartat, s'analitzarà els tipus d'atributs que es tenen i, si no està estipulat, **caldrà fixar quin és l'atribut objectiu a classificar de tots els que hi ha a la base de dades**.\n",
    "Expliqueu a la memòria quin atribut heu fet servir, no hi ha una decisió única correcta, cal que doneu raons de per què heu triat l'atribut que hàgiu triat.\n",
    "\n",
    "Treballarem varis aspectes de la classificació:\n",
    "\n",
    "1. EDA (exploratory data analysis)\n",
    "2. Preprocessing (normalitzation, outlier removal, feature selection..)\n",
    "3. Model Selection\n",
    "4. Crossvalidation\n",
    "5. Metric Analysis\n",
    "6. Hyperparameter Search\n",
    "\n",
    "\n",
    "Durant els següents apartats, es recomana anar fent una taula amb el mètode, paràmetres i precisió obtinguda. D'aquesta manera serà més fàcil entendre i valorar què s'aconsegueix en cada metode. Exemple:\n",
    "\n",
    "<img src=\"images/table_1.png\" width=\"80%\">\n",
    "\n",
    "Les preguntes de cada apartat són orientatives. **NO** cal contestar-les totes, ni totes tindrán sentit per tots els datasets. Són una guia per a que reflexioneu i aprengueu detalls de cada apartat. Tot i no ser obligatories, si que són molt recomenades d'intentar respondre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcio per a llegir dades en format csv\n",
    "import pandas as pd\n",
    "def load_dataset(path):\n",
    "    dataset = pd.read_csv(path, header=0, delimiter=',')\n",
    "    return dataset\n",
    "\n",
    "# Carreguem dataset d'exemple\n",
    "df = load_dataset('pokemon.csv')\n",
    "\n",
    "df.at[773, 'capture_rate'] = '30'\n",
    "df.at[773, 'attack'] = np.int64(60)\n",
    "df.at[773, 'defense'] = np.int64(100)\n",
    "df.at[773, 'sp_attack'] = np.int64(60)\n",
    "df.at[773, 'sp_defense'] = np.int64(100)\n",
    "df.at[773, 'speed'] = np.int64(60)\n",
    "df.at[773, 'base_total'] = np.int64(440)\n",
    "\n",
    "df['capture_rate'] = df['capture_rate'].astype(np.int64)\n",
    "df['genderless'] = df['percentage_male'].isnull() + 0\n",
    "\n",
    "data = df.values\n",
    "labels = df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EDA (exploratory data analysis)\n",
    "\n",
    "Igual com a la pràctica anterior, exploreu i visualitzeu com és la base de dades que teniu assignada.\n",
    "\n",
    "**Preguntes:**\n",
    "* Quants atributs té la vostra base de dades?\n",
    "    * _**Resposta:** La nostra base de dades té 41 atributs._\n",
    "* Quin tipus d'atributs tens? (Númerics, temporals, categorics, binaris...)\n",
    "    * _**Resposta:** Els tipus d'atributs que tenim són els següents:_\n",
    "    | Atribut | Tipus | Descripció |\n",
    "    | :-- | :-: | :-- |\n",
    "    |name| String, categoric |The English name of the Pokemon|\n",
    "    |japanese_name| String, categoric |The Original Japanese name of the Pokemon|\n",
    "    |pokedex_number| Numeric |The entry number of the Pokemon in the National Pokedex|\n",
    "    |percentage_male| Numeric. |The percentage of the species that are male. Blank if the Pokemon is genderless.|\n",
    "    |type1| String, categoric |The Primary Type of the Pokemon|\n",
    "    |type2| String, categoric |The Secondary Type of the Pokemon|\n",
    "    |classification| String, categoric |The Classification of the Pokemon as described by the Sun and Moon Pokedex|\n",
    "    |height_m| Numeric |Height of the Pokemon in metres|\n",
    "    |weight_kg| Numeric |The Weight of the Pokemon in kilograms|\n",
    "    |capture_rate| Numeric |Capture Rate of the Pokemon|\n",
    "    |baseeggsteps| Numeric |The number of steps required to hatch an egg of the Pokemon|\n",
    "    |abilities| String |A stringified list of abilities that the Pokemon is capable of having|\n",
    "    |experience_growth| Numeric |The Experience Growth of the Pokemon|\n",
    "    |base_happiness| Numeric |Base Happiness of the Pokemon|\n",
    "    |against_?| Numeric |Eighteen features that denote the amount of damage taken against an attack of a particular type|\n",
    "    |hp| Numeric |The Base HP of the Pokemon|\n",
    "    |attack| Numeric |The Base Attack of the Pokemon|\n",
    "    |defense| Numeric |The Base Defense of the Pokemon|\n",
    "    |sp_attack| Numeric |The Base Special Attack of the Pokemon|\n",
    "    |sp_defense| Numeric |The Base Special Defense of the Pokemon|\n",
    "    |speed| Numeric |The Base Speed of the Pokemon|\n",
    "    |generation| Numeric |The numbered generation which the Pokemon was first introduced|\n",
    "    |is_legendary| Binary |Denotes if the Pokemon is legendary|\n",
    "    |genderless| Binary |Denotes if the Pokemon has a gender|\n",
    "  \n",
    "* Com es el target, quantes categories diferents existeixen?\n",
    "    * _**Resposta:** El nostre target és 'is_legendary', i, com que és una dada binària, té dues categories (una per a Pokemon legendaris, l'altra per a no legendaris)._\n",
    "\n",
    "* Podeu veure alguna correlació entre X i y?\n",
    "    * _**Resposta:** Sí._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# ↓↓ Let's remove the \"against_?\" attributes, since we've been told they give us no information.\n",
    "df_mod = df.drop(columns=[l for l in labels[range(1,19)]])\n",
    "correlacio = df_mod.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Mirem la correlació entre els atributs per entendre millor les dades\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mod.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirem la relació entre atributs utilitzant la funció pairplot\n",
    "# relacio = sns.pairplot(df_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = df_mod.columns.values\n",
    "for i in [_ for _ in range(24) if _ != 22]:\n",
    "    try:\n",
    "        # sns.histplot(df_mod, x=labels[i], hue=labels[22], multiple=\"layer\", element='poly')\n",
    "        sns.histplot(df_mod, x=labels[i], hue=labels[22], multiple=\"stack\")\n",
    "        plt.subplots(figsize=(10, 10))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Estan balancejades les etiquetes (distribució similar entre categories)? Creus que pot afectar a la classificació la seva distribució?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing (normalitzation, outlier removal, feature selection..)\n",
    "Un cop vistes les dades de les que es disposa, per tal de tenir un aprenentatge més eficient, es recomana normalitzar les dades i treure outliers. Segons la tipologia de dades, es poden filtrar atributs, aplicar-hi reductors de dimensionalitat, codificar categories textuals en valors numèrics..\n",
    "\n",
    "Navegueu per la [documentació de sklearn sobre preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) per tal de trobar les diferents opcions que proporciona sklearn.\n",
    "\n",
    "**Preguntes:**\n",
    "* Estàn les dades normalitzades? Caldria fer-ho?\n",
    "* En cas que les normalitzeu, quin tipus de normalització será més adient per les vostres dades?\n",
    "* Teniu gaires dades sense informació? Els NaNs a pandas? Tingueu en compte que hi ha metodes que no els toleren durant el aprenentatge. Com afecta a la classificació si les filtrem? I si les reompliu? Com ho farieu? [Pista](https://scikit-learn.org/stable/modules/impute.html)\n",
    "* Teniu dades categoriques? Quina seria la codificació amb més sentit? (`OrdinalEncoder`, `OneHotEncoder`, d'altres?)\n",
    "* Caldria aplicar `sklearn.decomposition.PCA`? Quins beneficis o inconvenients trobarieu?\n",
    "* Es poden aplicar `PolynomialFeatures` per millorar la classificació? En quins casos té sentit fer-ho?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Selection\n",
    "La tasca d'aquesta pràctica s'enmarca dins l'aprenentatge computacional **supervisat**. A sklearn, disposem de varies tècniques [(veure documentació)](https://scikit-learn.org/stable/supervised_learning.html). A les classes de teoria, hem vist varies tècniques, com ara logistic regression, SVM amb diferents kernels, Nearest Neighbour, i el perceptró...\n",
    "En aquesta secció heu de valorar quina o quines tècniques voleu fer servir, aixi com també explicar el per què les heu seleccionat. Recomanem, que per entendre millor la teoria, s'ha de provar com a mínim un model de SVM.\n",
    "\n",
    "**Preguntes:**\n",
    "* Quins models heu considerat?\n",
    "* Considereu les SVM amb els diferents kernels implementats.\n",
    "* Quin creieu que serà el més precís?\n",
    "* Quin serà el més ràpid?\n",
    "* Seria una bona idea fer un `ensemble`? Quins inconvenients creieu que pot haver-hi? [Documentació](https://scikit-learn.org/stable/modules/ensemble.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Crossvalidation\n",
    "Un cop seleccionats quins models es volen testejar sobre les dades, s'han de poder evaluar correctament. Per aquests motius, haurem d'aprendre a cros-validar els resultats.\n",
    "Reviseu la [documentació](https://scikit-learn.org/stable/modules/cross_validation.html) i escolliu quin tipus de crossvalidació pot ser l'adecuada pel vostre problema.\n",
    "\n",
    "**Preguntes:**\n",
    "* Per què és important cross-validar els resultats?\n",
    "* Separa la base de dades en el conjunt de train-test. Com de fiables serán els resultats obtinguts? En quins casos serà més fiable, si tenim moltes dades d'entrenament o poques?\n",
    "* Quin tipus de K-fold heu escollit? Quants conjunts heu seleccionat (quina k)? Com afecta els diferents valors de k?\n",
    "* Es viable o convenient aplicar `LeaveOneOut`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Metric Analysis\n",
    "En aquest apartat ens centrarem en les mètriques de classificació ([documentació](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)).\n",
    "\n",
    "**Preguntes:**\n",
    "* A teoria, hem vist el resultat d'aplicar el `accuracy_score` sobre dades no balancejades. Podrieu explicar i justificar quina de les següents mètriques será la més adient pel vostre problema? `accuracy_score`, `f1_score` o `average_precision_score`.\n",
    "* Mostreu la Precisió-Recall Curve i la ROC Curve. Quina és més rellevant pel vostre dataset? Expliqueu amb les vostres paraules, la diferencia entre una i altre [Pista](https://stats.stackexchange.com/questions/338826/auprc-vs-auc-roc)\n",
    "* Què mostra [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)? Quina métrica us fixareu per tal de optimitzar-ne la classificació pel vostre cas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter Search\n",
    "El motiu d'aplicar crossvalidació durant l'entrenament és que ens permet conèixer quin serà el resultat esperat del nostre model un cop en producció, és a dir, com es comportarà sobre dades mai vistes abans.\n",
    "A més, també ens permet optimitzar quins són els hiperparametres dels models que millor funcionaran en el futur test.\n",
    "\n",
    "**Preguntes:**\n",
    "* Quines formes de buscar el millor parametre heu trobat? Són costoses computacionalment parlant? [documentació](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "* Si disposem de recursos limitats (per exemple, un PC durant 1 hora) quin dels dos métodes creieu que obtindrà millor resultat final?\n",
    "* Existeixen altres mètodes de búsqueda més eficients ([scikit-optimize](https://scikit-optimize.github.io/stable/))?\n",
    "* Feu la prova, i amb el model i el metode de crossvalidació escollit, configureu els diferents metodes de búsqueda per a que s'executin durant el mateix temps (i.e. depenent del problema, 0,5h-1 hora). Analitzeu quin ha arribat a una millor solució. (estimeu el temps que trigarà a fer 1 training, i aixi trobeu el número de intents que podeu fer en cada cas.)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
